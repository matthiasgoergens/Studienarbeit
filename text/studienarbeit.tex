\documentclass[a4paper]{amsart}

%\usepackage{palatino}
%\usepackage{euler}
\usepackage{charter}
%\usepackage{computermodern}

\usepackage{amsfonts}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bbm}

\usepackage{listing}

\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{defn}[theorem]{Definition}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\usepackage{units}
%\usepackage{icomma}

\usepackage{psfrag, graphicx}
\usepackage{url}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{longtable}
\usepackage{booktabs}
\setcounter{LTchunksize}{1000}



\graphicspath{{img/}}
\author{Matthias Görgens}

% ---- LATIN ----
\def\etal{\emph{et~al.}}
\def\ie{\emph{i.e.}}
\def\Ie{\emph{I.e.}}
\def\eg{\emph{e.g.}}
\def\Eg{\emph{E.g.}}
\def\vitae{vit\ae{}}
\def\apriori{\emph{a~priori}}
\def\aposteriori{\emph{a~posteriori}}

% ---- FRENCH ----
\def\naive{na\"{\i}ve}
\def\Naive{Na\"{\i}ve}
\def\naively{na\"{\i}vely}	% Okay, I know, this isn't French.
\def\Naively{Na\"{\i}vely}

\DeclareMathOperator{\In}{in}
\DeclareMathOperator{\Out}{out}
\DeclareMathOperator{\conv}{conv}


%für ein/aus-gehende kanten
\newcommand{\ina}{\ensuremath{\vec{\In}}}
\newcommand{\outa}{\ensuremath{\vec{\Out}}}

\newcommand{\lex}{\ensuremath{\prec}} % \leq_{\mathop{lex}}}}

%für knoten ein/aus-gehender kanten.
\newcommand{\inv}{\ensuremath{\dot{\In}}}
\newcommand{\outv}{\ensuremath{\dot{\Out}}}

\newcommand\mpar[1]{\marginpar {\flushleft\sffamily\small #1}}
\setlength{\marginparwidth}{3cm}
\setlength{\marginparpush}{1cm}

\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\todo}[1]{\mpar{#1}}
%\newcommand{\todo}[1]{\footnote{#1}}

% lr stands for left,right
\newcommand{\lr}[1]{\ensuremath{\left( #1 \right)}}
% and for equivalency classes
\newcommand{\lrE}[1]{\ensuremath{\left[ #1 \right]}}
% and Mengen
\newcommand{\lrM}[1]{\ensuremath{\left\{ #1 \right\}}}
\newcommand{\lrX}[1]{\ensuremath{\left< #1 \right>}}

\newcommand{\abs}[1]{\ensuremath{\left| #1 \right|}}

\newcommand{\reals}{\ensuremath{\mathbb{R}}}
\newcommand{\naturals}{\ensuremath{\mathbb{N}}}
\newcommand{\rationals}{\ensuremath{\mathbb{Q}}}

\newcommand{\Hom}{\ensuremath{\mathrm{Hom}}}

\newcommand{\M}{\ensuremath{\mathcal{M}}}
\newcommand{\Sym}{\ensuremath{\mathfrak{S}}}

\usepackage{hyperref}
\begin{document}

\title{Partinioning Orbitopes for Permutation of Rows and Columns -- Term Paper}
\maketitle
%\section{Abstract}


\section{Introduction}
Symmetry pops up in places as diverse as aesthetics, and conserved
physical quantities.  Or algorithmic problem solving: Say, you are
given a problem that consists of many independent but similar
subproblems, like doing some calculation with all numbers in a list.
Your solution can exploit the problem's symmetry of repetition: ``Just
do the same operation for each element of the list and collect the
results.''% -- or, if you want to be more formal and use a programming
%language (\eg{} Haskell): \todo{Oder lieber mit Funktoren?  Oder ganz informell?}
%%TeXify Haskell
%\begin{verbatim}
%solution :: [Input] -> [Output]
%solution = fmap operation
%\end{verbatim}
%You may even calculate in parallel.

But symmetry can also be a problem.  Take Buridan's ass.
\todo{Recherche, about name and so on} Placed exactly at the midpoint
between two equally enticing haystacks, the philosopher's ass can not
decide where to go and starves \todo{kl"aglich!}.  Of course even if
such an exact placement was possibly, no real donkey \todo{synonym
  ok?} would have a problem making an arbitrary choice for one of the
stacks.  However contrived the relation to a real animal, Buridan's
ass does bear some resemblance to computer programs.  One has to teach
them explicitly how to make arbitrary decisions to get out of these traps.

Programs for solving linear integer optimization problems have often
been caught between haystacks, forced to evaluate all possibilities
and not deciding until the last moment.  The introduction and analysis
of orbitopes has been one recent step towards fashioning those
programs with more judgement to cut short their search for the
optimum.  Orbitopes exploit the situation where one can introduce
groups acting on the feasible solutions of an integer problem such
that members of the same orbit share the same objective value.
Obviously, any optimization algorithm that only considers at least one
representative of each orbit will still find an optimal solution, if
there is one.  Orbitopes are the convex hulls of all representatives
thus considered.  It is customary to take the lexicographically
smallest member of each orbit as its representative.

In this paper I will consider a certain kind of partitioning
orbitopes.  Partitioning orbitopes are polytopes that live in the set
of \(0/1\)-matrices with at most, resp. exactly, one 1-entry per row.
Matrices that can be transformed into each other by permutation of
columns are considered equal and belong to one orbit.  The
partitioning orbitopes are inclusion minimal polytopes that contain
one and only one member from each orbit: the unique representative
matrix with lexicographically descending sorted columns.  (Henceforth
we will silently imply lexicographically whenever we speak of
``biggest'', or ``least'', and furthermore imply descending order with
``sorting'', .)

In \cite{faenza-2008} Faenza and Kaibel give compact extended
formulations for the packing and partitioning orbitopes.  In this
paper I want to review symmetric partitioning orbitopes: In addition
to column permutation allowed for mere partitoning orbitopes, row
permutations are allowed as well.  I will give an extended formulation
for symmetric partitioning orbitopes with full row symmetry. And I
will show that optimization over symmetric partitioning orbitopes can
be an NP-hard problem \todo{or NP complete?} with certain other groups
acting on the rows.


% Consider the very special instance of the partioning problem of
% partitioning the $p$ nodes of complete graph into at most $q$ parts.
% One well-known formulation uses variables $x_{ij}$ to indicate whether
% node $i$ is put into part $j$.

\section{Definitions}
We will use the notation introduced in \cite{orbi} by Pfetsch
and Kaibel.  Let \(\mathbbm{1}_{p,q} \in \lrM{1}^{\lrE{p}
  \times \lrE{q}}\) be the matrix composed of one-entries of size \(p \times q\).
Let \(\M_{p,q} = \{0, 1\}^{p \times q} \). 

\begin{defn}[Partitioning and Packing Matrices]
  For some size \(p, q \in \naturals^{>0}\) consider the sets of
  matrices \(\M_{p,q}^{=},\M_{p,q}^{\leq} \subseteq \M_{p, q}\), such
  that 
  \begin{align}
    \M_{p,q}^{=} & := \lrM{m \in \M_{p,q} \mid m \cdot \mathbbm{1}_{q, 1} = \mathbbm{1}_{p, 1}} & \text{(Partitioning Matrices)}\\
    \M_{p,q}^{\leq} & := \lrM{m \in \M_{p,q} \mid m \cdot \mathbbm{1}_{q, 1} \leq \mathbbm{1}_{p, 1}} & \text{(Packing Matrices)}
  \end{align}
  (\Ie{} consider the matrices with exactly one 1-entry per row and the matrices with at most one 1-entry per row.)
\end{defn}

 \begin{defn}[Orbitopes]
   Let \(G\) be a group acting on a set \(A \subseteq \rationals^{p,q}\).  Let \(A\) have a total order \(\lex\), such that \(a\lex b \lex a\) implies \(a = b\).
   Look at the set \(V \subseteq A\) uniquely determined by
   \begin{align}
       v  \lex  G \cdot v  \text{ for all } v \in V
     \end{align}
   and
   \begin{align}
     G \cdot V =  A \text{.}
   \end{align}
   Call its convex hull \(O_{\lex} \lr{G, A} := \conv{}  V\) the orbitope of
   \(G\) on \(A\) with ordering \(\lex\).  
 \end{defn}
\begin{remark}
  We will omit stating the ordering and imply lexicographic ordering
  on the matrices, where entries with lexicographically lower indices
  are considered more significant.  For example
  \[\lr{\begin{matrix}
      1 & \mathbf{2} \\
      3 & 4 \\
      \end{matrix}
    }
    \lex
    \lr{\begin{matrix}
      1 & \mathbf{3} \\
      2 & 4 \\
      \end{matrix}
    }\text{.}
  \]
\end{remark}
\begin{remark}
  Our definition of orbitopes is slightly more generalized than the definition in \cite{orbi}.
\end{remark}

Kaibel and Fetsch talk about orbitopes for partitioning and packing
matrices.  In associated problems the labels of the partitions can
often be exchanged without altering the quality of a solution.  For
example in the graph coloring problem the colors can be permuted.  For
the matrices this means that we can let a symmetric group act on the
columns.

\begin{defn}[Columns and Rows]
  Fix \(p, q \in \naturals^+\).  Consider the set of matrices \(M :=
  \mathbb{C}^{p \times q}\).  Let \(R_i := M_{i, *}\) be the \(i\)-th
  row of those matrices, and let \(R\) be the set of all rows.
  \(\Sym_R\) shall designate the symmetric group over them.  Define
  \(C_j\), \(C\) and \(\Sym_C\) in analogue for the columns.  Call
  \(\Sym_{R \times C} := \Sym_R \times \Sym_C\).  As an abuse of
  notation --- if it is clear from the context that a specific matrix
  \(m \in M\) is meant, \(R\) and \(C\) can also refer to the rows
  and columns of that specific matrix.  We will also usually supply \(p\)
  and \(q\) by context only.
\end{defn}

% Often we face a optimization problems over partitioning
% matrices where the action of \(\Sym_C\) on the columns conserves
% feasibility and objective values; then restricting the space of
% solutions to the orbitope of \(\Sym_C\) on \(O^=\) conserves the
% occurrence\footnote{and non-occurrence} of all objective values ---
% obviously including the optimum.  Thus the following definition:

%More formally the group \(S = S_R \times S_C\) acts on the solution,
%where \(S_R\) and \(S_C\) are the symmetric groups on rows and
%columns.  The next section gives a description of the representatives
%contained in a symmetric partitioning orbitope.

\begin{defn}[Packing and Partitioning Orbitopes]
  We will work with the following two orbitopes
  \begin{description}
    \item[Partitioning orbitope] \(O^=_C := O \lr{S_C, \M_{p,q}^=}\)
    \item[Packing orbitope] \(O^{\leq}_C := O \lr{S_C, \M_{p,q}^=}\)
   \end{description}
\end{defn}

In this paper we will have a look at even more symmetric problems.
Here not only the columns can be permuted but also the rows.  For
example take vertex coloring on a graph whose automorphism group is
isomorphic to the symmetric group on its vertices.  Rows correspond to
vertices and columns to a colors.

\begin{defn}[Symmetric Partitioning and Packing Orbitopes]
%  \label{espo}
Introduce the following orbitopes:
\begin{description}
\item[Symmetric partitioning orbitope] \(\mathcal{O}^=_{p,q} := O^=_{p, q} \lr{\Sym_{R \times C}} \)
\item[Symmetric packing orbitope] \(\mathcal{O}^\leq_{p,q} := O^\leq_{p, q} \lr{\Sym_{R \times C}} \)
\end{description}
\end{defn}



%\begin{defn}[Partial Symmetric Partitioning Orbitope]
%  Add definition
%\todo{add definition}
%\end{defn}

\section{Vertices of the Symmetric Partitioning Orbitope}
\todo{Komplett ueberarbeiten.}  Let's take a closer look at the
vertices of the partitioning orbitope \(O^=_{R \times C}\) of size
\(p, q \in \naturals^{>0}\).

\begin{remark}
  Note that \(O^=_{R \times C} \subsetneq O^=_{R} \cap O^=_{C}\).  In
  general expressing the orbitope of an internal direct product in
  terms of the orbitopes of both factor groups is a hard problem.
\end{remark}

%  Let \(p\) be the number of columns and \(q\) be the number of rows of
%  matrices in the set \(\M_{p,q} \subseteq \left\{0, 1\right\}^{p\times q}\) of all
%  \(0/1\)-matrices with exactly one 1-entry in each row.  Let \(S = S_R
% \times S_C\) be the Cartesian product of the symmetric groups on rows
%  and columns.  \(S\) acts on \(\M_{p,q}\).

%  Sortierung der Zeilen reicht auch schon für simple s.p.o.

% Obviously we can require representatives to be lexicographically
% sorted along rows and columns.  Thus we get representative matrices
% with 1 in the top-left.  In each row the 1-entry stays in the column
% it dwelled in the row above -- or wanders off one column right.  In
% fact sorting along the rows is sufficent for this normal form; sorting
% the columns does not add to the requirements.

Using a very simple flow network one can easily find the facettes of
the resulting \textit{simple symmetric partition orbitope} -- see
\ref{fluss}.

% sort columns by hamming distance

Unfortunately this way some orbits of $S$ intersect the orbitope with
more than one member.  To guarantee exactly one representative per
orbit we restrict the orbitope further:


Computer generated examples suggest that no polynomial in \(p \cdot
q\) limits the number of  symmetric partioning orbitope's
facettes.

But - I will show an extended formulation for \(S^=_{p, q}\) by linear
inequalities that is polynomially bounded in number of both variables
and facettes in \(p \cdot q\).


% \section{Facettes of the Simple Symmetric Partitioning Orbitope}
% %Bild!

% The simple symmetric partitioning orbitope permits an efficient
% description by equalities and inequalities in the original space of
% variables.

% % 1  1  1
% %-1 -1 -1

% %-1 -1 -1
% % 1  1  1  1

\section{Polynomial Optimization on the  Symmetric Partitioning
  Orbitope}
\label{fluss}
We will reduce maximization over the orbitope to finding a longest
\(s\)-\(t\)-path in an acyclic weighted digraph.

\subsection{Setup}

Let \(p, q \in \mathbb{N} \setminus \{0\}\).  Given a matrix \(M \in
\mathbb{Q}^{p \times q}\) of objective values, consider the program:
\begin{equation}
\label{optS}
\max \left<M, \mathbf{x} \right>  \text{ s.t. } x \in S^=_{p, q}
\end{equation}
where \[\left<M, \mathbf{x} \right> := \sum_{(i, j)\in [p]\times [q]} x_{i, j}\cdot M_{i, j}\text{.}\]
We will construct a acyclic weighted graph \(D := (V, A)\) to project each vertex of
\(S^=_{p, q}\) and its objective value to one \(s\)-\(t\)-path in \(D\) and its length.

Define the vertex set:
\[V := \left( [p]\times [q] \times [p]\right) \uplus \{s\} \uplus \{t\}\text{.}\] 
Each \textit{ordinary} vertex, that is
each vertex besides \(s\) and \(t\), encodes a row, a column and the
maximum Hamming weight per column still allowed.

The arcs \(A := \overline{A} \uplus A_t\) can be described as a union
of ordinary arcs \(\overline{A}\) and arcs \(A_t\) ending in \(t\).  Setting
\(s:=(0, 0, q)\) allows the arcs from $s$ to be formalized as
ordinary arcs.
\begin{align}
  \overline{A} &:=
  \left\{ \left(r, c, h\right) \rightarrow \left(r+h', c+1, h'\right) \in V \times V \colon
  h' \leq h \right\} \\
  A_t &:= ([p] \times {q} \times [p]) \times \{t\}
\end{align}

For parent and child nodes and arcs we will use the following notation:
\begin{align*}
\ina\colon  V &\to \mathcal{P}(A) \\
v &\mapsto \left(V \times \{v\}\right) \cap A\\
%\end{align*}
%\begin{align*}
\outa\colon  V &\to \mathcal{P}(A) \\
v &\mapsto \left(\{v\} \times V\right) \cap A\\
%\end{align*}
%\begin{align*}
\inv\colon  V &\to \mathcal{P}(V) \\
v &\mapsto \left\{ u \colon \left(u, v\right) \in \ina(v) \right\}\\
%\end{align*}
%\begin{align*}
\outv\colon  V &\to \mathcal{P}(V) \\
v &\mapsto \left\{w \colon \left(v, w\right) \in \outa\left(v\right) \right\}\\
\end{align*}

To link objective values over \(S^=_{p, q}\) with
\(s\)-\(t\)-path-lengths in \(D\) we introduce arc weights \(m\colon A \to \mathbb{Q}\).
\begin{align}
\label{objLink}
  m\left(\left(r, c, h\right) \rightarrow \left(r+h', c+1, h'\right) \right) & := \sum_{i=r+1}^{r+h'} M_{i, c+1} \\
  m\left(\left(r, c, h\right) \rightarrow t \right) & := 0
\end{align}

% \subsection{Finding the Longest \(s\)-\(t\)-Path in \(D\)}
\subsection{Finding the Longest s-t-Path in D}
\todo{Change to the math-version of the subsection headline}

Call \(P_s \colon V \to A^* \) the function that maps each node \(v\)
to the longest path connecting \(s\) and \(v\).  Here \(A^*\) means
the Kleene closure of \(A\): I.e. the set of all strings of arcs \(a
\in A\) including the empty string.  Also set 
\begin{align*}
m \colon A^* &\to \mathbb{R} \\
\omega &\mapsto \sum_{a\in \omega} m \left(a \right)
\end{align*}

To find the longest \(s\)-\(t\)-path in \(D\) is to calculate
\(P_s (t)\).  Dynamic programming lends itself to this task.  Since
\(D\) is acyclic we start knowing \(P_s (s) = \lambda\).

For each \(v \in V\) for which \(P_s (v)\) is unknown but for whose
every parent \(w \in \inv(v)\) the path \(P_s (w)\) is already known,
we conclude
\[m\left(P_s \left(v\right)\right) = \max_{w \in \inv(v)}
m\left(P_s(w) \cdot \left(w \rightarrow v \right) \right)\text{.}\]

The graph \(D\) admits at least one trivial path from \(s\) to \(t\).
Together with the acyclic and finite nature of \(D\) this guarantees that we
learn \(P_s (t)\) eventually.  More specifically we get to know \(P_s
(t)\) after looking at each arc of \(D\) at most a constant number of
times.

%the
%following dynamic programming technique: Since \(D\) is an acyclic
%digraph we can sort its vertices topologically.

%Afterwards for each node \(v\) in topological order we calculate the
%longest \(s\)-\(v\) path and distance based on the known longest
%\(s\)-\(w\)-distances

%Topologische Sortierung, 

%Bilder!

\section{Extended Formulation for the Symmetric Partitioning Orbitope}
The aforementioned Graph \(D\) can be used to derive an extended
formulation for the  symmetric partitioning orbitope.  For this
formulation we have to construct a linear description of finding the
longest path in a digraph.  Fortunately -- as it is well known --
network flows do the trick.  The transformation from network flows
back to the original variable space of \(S^=_{p, q}\) can be done with
a linear function, as well.

We introduce flow variables \(f \in \mathbb{R}^A_{\geq 0}\).  

For sets \(M\) we define
\[f (M) := \sum_{m\in M} f(m)\text{.}\]

Now, we can begin with the extendend formulation for the 
symmetric partitioning orbitope.  For each vertex \(v \in V \setminus
\{s, t\}\) we have:
\begin{equation}
f\left(\ina(v)\right) = f\left(\outa(v)\right)
\end{equation}
and for \(s\) we get:
\begin{equation}
f\left(\outa(s)\right) = 1
\end{equation}

% subto coupling:
% forall <sx, cx> in Y:
%        y[sx,cx] == sum <s, c, h, s_, c_, h_> in A
%               	   with c+1 == cx
% 		   and cx == c_
% 	    	   and s < sx and sx <= s_ :
% 	   	   f[s, c, h, s_, c_, h_];


To link \(f\) with \(x\) of our original problem (\ref{optS}) we
introduce the following conditions that are in analogue to \ref{objLink}:
%TODO: nachschauen, wie man die Indexbereiche unter der Summe stapelt
\begin{equation}
  x \left( r, c \right) =
  \sum_{r' - h' \leq r \leq r'; h' \leq h} f\left(\left(r'-h', c-1, h\right)
    \rightarrow \left(r', c, h'\right) \right)
2\end{equation}

\section{Restricting the Symmetric Group}

Allowing permutations of all columns and a subset of rows produces an
NP-hard optimization problem in general.  This can be shown by
reducing another problem, that is already proven to be NP-hard.

\begin{defn}[Partial symmetric partitioning orbitope]
  \label{def-subset-rows}
  Fix \(p, q \in \naturals^+\).  Fix a subset \(J \subseteq \lrE{p}\).
  Call \(\Sym_{J}\) the symmetric group acting on \(R_J\) of \(\M^=_{p, q}\).
  Define \(\mathcal{O}^=_{p,q}\lr{J} := O^=_{p, q} \lr{\Sym_{J} \times \Sym_{C}} \) as the partial symmetric partitioning orbitope.
\end{defn}

\todo{Describe lexicographically maximal elements of the orbits of
  \(\Sym_J \times \Sym_C\)} Let's examine the vertices of
\(\mathcal{O}^=_{p,q}\lr{J}\), \ie{} the lexicographically maximal
elements of the orbits of \(\Sym_J \times \Sym_C\) acting on \(\M^=_{p,q}\).

\begin{theorem}[Subset of rows]
  \label{subset-rows}
  Optimizing a linear function \(d \in \Hom\lr{\rationals^{p,q},\rationals}\) over the partial symmetric partitioning orbitope
  \(\mathcal{O}^=_{p, q}\lr{I}\) is NP-hard in \(\lrX{d}+\lrX{I}\).
\end{theorem}

For the proof of theorem \ref{subset-rows}, we will need a result by
Kaibel and Peinhardt\todo{Wer noch? + Quelle}:

\begin{theorem}[``Pairwise permutations of columns are NP-hard'']
  \label{pairwise}
  For some \(p, q \in \naturals^+\) consider the packing matrices
  \(\M^=_{p \times q}\).   \todo{Ist das so korrekt formuliert?} Choose some mutually disjoint pairs of
  adjacent columns, call their indices \(I\) with \(\lr{I + 1} \cap I
  = \emptyset\) and \(I \subseteq \lrE{q}\).
  Let 
  \[P_I := \prod_{i \in I} \Sym_{\lrM{C_{i}, C_{i+i}}}\] 
  be the cartesian product of symmetric groups acting on those pairs.
  Optimizing a linear objective function \(c \in \Hom\lr{\rationals^{p \times
    q}, \rationals}\) over \(O^=_{p, q} \lr{P_I}\) is NP-hard in
  \(\lrX{I}+\lrX{c}\).
\end{theorem}

\begin{proof}[Proof of `Subset of rows']
  We prove \ref{subset-rows} by reducing the problem given in
  \ref{pairwise} to the subset-of-rows problem: Given the linear
  objective function in \(\Hom \lr{\M^=_{p, q}, \rationals} \), we
  will extend it upwards to a function in \(\Hom \lr{\M^=_{e+p, q},
    \rationals}\) on a set of much taller partitioning matrices.  The
  extra co\"efficients at the top will encode the structure of the
  disjoint pairs of columns: We will force both elements of any
  commuting column pair in the original problem, to have the same
  number of ones in the upper part of the extended matrix.
  %% Since we only include lexicographically maximal elements of 

  Fix a size \(p, q\), an objective function \(c\) and pairs of
  columns \(I\) as in the statement of theorem \ref{pairwise}.  Assume
  -- without loss of generality -- that we are maximizing \(c\) on
  \(\M^=_{p,q}\).  Without fixing \(e\) yet, embed \(\M^=_{p,q}\) at
  `the bottom of' \(\M^=_{e+p,q}\), \ie
  \begin{align}
    \varphi \colon \M^=_{p,q} & \to \M^=_{e+p,q} \\
    \nonumber
     m & \mapsto \lr{\begin{matrix}
       \mathbf{0} \\
       m
     \end{matrix}}
 \end{align}
 And to get back, use the projection \(\pi\):
 \begin{align}
   \pi \colon \M^=_{e+p,q} & \to \M^=_{p,q} \\
    \nonumber
     \lr{\begin{matrix}
         l \\
         m
     \end{matrix}} & \mapsto m
  \end{align}
  We will call the complementary projection \(\pi^\bot\):
  \begin{align}
    \pi^\bot \colon \M^=_{e+p,q} & \to \M^=_{e,q} \\
    \nonumber
    \lr{\begin{matrix}
        l \\
        m
      \end{matrix}} & \mapsto l
  \end{align}
  Let \(J := \lrE{e}\) and define \(\Sym_{J}\) as in
  \ref{def-subset-rows}.  How can the upper \(e\) rows encode \(I\)?
  
  We want to force the upper \(e\) rows so that columns that permute
  in \(P_I\) have the same number of 1-entries.  The number of
  1-entries per column can not increase as we go from left to
  right. \todo{Describe the vertices above.}

  So we choose the number \(\Delta\lr{j}\) of ones per column \(j\) such that
  \begin{align}
    \Delta \lr{j+1} & =  \Delta \lr{j} - \begin{cases} 0 & \text{if } j \in I\\
      1 & \text{otherwise} \\
    \end{cases}\\
    \Delta \lr{q} & = 0 \text{.}
  \end{align}
  Now, number of zeros \(o\lr{j}\) in a column \(j\) above the first one is governed by the following two equations
\begin{align}
  o \lr{j+1} & = o \lr{j} + \Delta \lr{j} + 1 \\
  o \lr{1} & = 0
 \end{align}
 Choose \(e := o\lr{q} + \Delta\lr{q} \leq \frac{q \lr{q+1}}{2}\) as
 the smallest number of rows that can accommodate all ones as given
 above.
 
 Now only the objective function \(d\) is left to be defined to
 actually enforce the structure of ones and zero that we desire:
 \begin{align}
   d & \in \Hom \lr{\rationals^{\lr{e + p} \times q}, \rationals} \\
   d_{i,j} & := \begin{cases} s+1 & \text{if } i \in \left[o\lr{j},o\lr{j}+\Delta\lr{j} \right]\\
     c_{i,j} & \text{if } i \geq o\lr{q}\\
     -s-1 & otherwise
     \end{cases}
 \end{align}
 Where \(s\) has to be chosen large enough, to force the upper part of
 the partition matrix no matter what the rest does:
 \begin{align}
   s := p \cdot \lr{\max_{i,j \in \lrE{p}\times \lrE{q}} c_{i,j}
     - \min_{i,j \in \lrE{p}\times \lrE{q}} c_{i,j}}
 \end{align}
 \(\lrX{d}+\lrX{J}\) is certainly polynomial in \(\lrX{c} + \lrX{I}\).  And to get from
 \begin{align}
   \hat{d} := \max d \lr{m} \text{ s.t. } m \in \mathcal{O}^=_{p, q}\lr{I}
 \end{align}
 to
 \begin{align}
   \hat{c} := \max c \lr{m} \text{ s.t. } m \in O^=_{p, q} \lr{P_I}
 \end{align}
 \todo{Why does the lower part of the new matrix resemble the old matrix?}
 you just exploit
 \begin{align}
   \hat{c} = \hat{d} - s \cdot e \text{.}
 \end{align}

\end{proof}

% For a natural number \(a \leq q\), let \(G_{Rows} = S_a\) act on
% the first \(a\) rows.  As usually \(G_{Columns} = S_p\) acts on
% all columns.  Look at the orbits of \(G_{Columns} \times G_{Rows}\)
% and take each orbit's lexicographically smallest member as its
% representative.

% \[\lrE{\lr{\begin{matrix}
% 1 & 0 & 0 \\
% 0 & 1 & 0 \\
% 0 & 1 & 0 \\
% 0 & 0 & 1\\
% \end{matrix}
% }}
% \]


% In a representative the columns will be sorted, and the last rows,
% too.  But we can demand even more.  Say \(a = 3\), then the following
% two matrices satisfy both condition, but are still in the same
% equivalency class:

% \[\lrE{\lr{\begin{matrix}
% 1 & 0 & 0 \\
% 0 & 1 & 0 \\
% 0 & 1 & 0 \\
% 0 & 0 & 1 \\
% \end{matrix}}} = \lrE{\lr{\begin{matrix}
% 1 & 0 & 0 \\
% 0 & 1 & 0 \\
% 0 & 1 & 0 \\
% 0 & 0 & 1 \\
% \end{matrix}}}
% \]



% [1 0 0
% ,0 1 0
% ,0 1 0
% ,0 0 1]

% [1 0 0
% ,0 1 0
% ,0 0 1
% ,0 0 1]

% S_t auf t-elementiger Teilmengen der Zeilen:
% z.B. erste t-Zeilen,
%      letzte t-Zeilen
% beliebige t-Zeilen (erstmal t=2)

%\section{Cartesian Products of Symmetric Groups}
%Kartesisches Produkt von symmetrischen Gruppen (vereinfachung?)

\bibliographystyle{plain}
\bibliography{quellen}

\end{document}
